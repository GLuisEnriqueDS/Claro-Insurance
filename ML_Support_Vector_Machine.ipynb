{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_excel(r'C:\\Users\\Usuario\\OneDrive\\Desktop\\Claro Insurance\\Data Science Projects\\04.11.24 Support Vector Machine\\data releases 04.15.24.xlsx',sheet_name='Train')\n",
    "predict= pd.read_excel(r'C:\\Users\\Usuario\\OneDrive\\Desktop\\Claro Insurance\\Data Science Projects\\04.11.24 Support Vector Machine\\data releases 04.15.24.xlsx',sheet_name='Predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado = data[data['Reason for Request'].isin(['Specific request Agency', 'Release Requested/ Whit out reason', 'Comfort Release',\n",
    "              'Another FMO', 'Independet FMO', 'Internal movement', 'Needed Accompaiment'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "swords = stopwords.words(\"english\")\n",
    "cleanedData=[]\n",
    "\n",
    "for text in df_filtrado[\"Observaciones.English\"]:\n",
    "    \n",
    "    text = re.sub(r'http\\S+', '', text) \n",
    "    text = re.sub(\"[^a-zA-Z0-9]\",\" \",text)\n",
    "    text = nltk.word_tokenize(text.lower())\n",
    "    text = [lemma.lemmatize(word) for word in text]\n",
    "    text = [word for word in text if word not in swords]\n",
    "    text = \" \".join(text)\n",
    "    cleanedData.append(text)\n",
    "    \n",
    "df_filtrado[\"Cleaned Data.English\"] = cleanedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los hiperparámetros que deseas ajustar y sus rangos\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Parámetro de regularización\n",
    "    'gamma': [0.1, 0.01, 0.001],  # Parámetro del kernel (solo para kernels 'rbf', 'poly', 'sigmoid')\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid']  # Tipo de kernel\n",
    "}\n",
    "\n",
    "# Inicializar el GridSearchCV con el modelo SVM y el espacio de hiperparámetros\n",
    "grid_search = GridSearchCV(SVC(class_weight=class_weights, probability=True), param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Ajustar el GridSearchCV a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores hiperparámetros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Mejores hiperparámetros encontrados:\", best_params)\n",
    "\n",
    "# Utilizar el modelo con los mejores hiperparámetros para hacer predicciones en el conjunto de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo con los mejores hiperparámetros\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                       Another FMO       0.50      0.33      0.40         3\n",
      "                   Comfort Release       1.00      1.00      1.00         1\n",
      "                    Independet FMO       1.00      0.50      0.67         2\n",
      "                 Internal movement       0.50      1.00      0.67         1\n",
      "               Needed Accompaiment       1.00      1.00      1.00         2\n",
      "Release Requested/ Whit out reason       1.00      0.50      0.67         2\n",
      "           Specific request Agency       0.67      0.86      0.75         7\n",
      "\n",
      "                          accuracy                           0.72        18\n",
      "                         macro avg       0.81      0.74      0.74        18\n",
      "                      weighted avg       0.76      0.72      0.71        18\n",
      "\n",
      "Accuracy of model is 72.22222222222221%\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df_filtrado['Cleaned Data.English'])\n",
    "y = df_filtrado['Reason for Request']\n",
    "\n",
    "# División de datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenamiento del modelo SVM\n",
    "class_weights = 'balanced'\n",
    "\n",
    "model = SVC(kernel='linear', class_weight=class_weights,probability=True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluación del modelo\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "\n",
    "print(\"Accuracy of model is {}%\".format(accuracy_score(y_test,y_pred ) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.6313552188552188\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Obtener las probabilidades de predicción para las clases\n",
    "y_probs = model.predict_proba(X_test)\n",
    "\n",
    "# Calcular el AUC\n",
    "auc = roc_auc_score(y_test, y_probs, average='weighted', multi_class='ovr')\n",
    "\n",
    "print(\"AUC score:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           NAME Create_Date         NPN                   NAME AGENT  \\\n",
      "0      201909-0  2019-07-08  18597037.0                 Miriam Nunez   \n",
      "1      201909-1  2019-07-25  18883037.0  Maria Cristina Boscan Devis   \n",
      "2     201909-10  2019-07-25  11058377.0              Yolanda Navarro   \n",
      "3     201909-11  2019-07-25  18193311.0               Darline Candio   \n",
      "4     201909-12  2019-09-19  15791397.0             Armando Portillo   \n",
      "..          ...         ...         ...                          ...   \n",
      "117  202210-141  2022-10-07  20124275.0         Yadira Perez Mendoza   \n",
      "118  202210-142  2022-10-12  19074059.0       Amalia Alvarez Tricera   \n",
      "119  202211-143  2022-11-10    626257.0           Lorri Ann Zelaznik   \n",
      "120  202212-144  2022-12-12  17355647.0            Sabrina Contreras   \n",
      "121   202005-39  2020-05-29         NaN                          NaN   \n",
      "\n",
      "                         ACCOUNT_NAME TIPO AGENTE  Reason for Request  \\\n",
      "0                     Claro Insurance     Directo                 NaN   \n",
      "1                     Claro Insurance     Directo                 NaN   \n",
      "2                     Claro Insurance     Directo                 NaN   \n",
      "3                     Claro Insurance     Directo                 NaN   \n",
      "4                 Insure Partners LLC     Agencia                 NaN   \n",
      "..                                ...         ...                 ...   \n",
      "117  A&G Salas Financial Services LLC     Agencia                 NaN   \n",
      "118                   Claro Insurance     Directo                 NaN   \n",
      "119                   Claro Insurance     Directo                 NaN   \n",
      "120     Prestige Insurance Consultant     Agencia                 NaN   \n",
      "121                               NaN         NaN                 NaN   \n",
      "\n",
      "     Final Premium                                      Observaciones  \\\n",
      "0              NaN                                                  0   \n",
      "1              NaN                                                  0   \n",
      "2              NaN                                                  0   \n",
      "3              NaN                                                  0   \n",
      "4              NaN  El día 19 de Sep se le solicita la información...   \n",
      "..             ...                                                ...   \n",
      "117            NaN  Favor dar release a esta agente. Fue solicitad...   \n",
      "118            NaN  La agente se encontraba interesada en crear un...   \n",
      "119            NaN  The agent doesn't want to continue working wit...   \n",
      "120            NaN  release solicitado por Luisa Alvarez para esta...   \n",
      "121            NaN  Via correo la agente solicita su release y Man...   \n",
      "\n",
      "                                 Observaciones.English  \\\n",
      "0                                                    0   \n",
      "1                                                    0   \n",
      "2                                                    0   \n",
      "3                                                    0   \n",
      "4    On September 19, information is requested from...   \n",
      "..                                                 ...   \n",
      "117  Please release this agent. It was requested di...   \n",
      "118  The agent was interested in creating an agency...   \n",
      "119  The agent doesn't want to continue working wit...   \n",
      "120  release requested by Luisa Alvarez for this ag...   \n",
      "121  Via email, the agent requests her release and ...   \n",
      "\n",
      "                                  Cleaned Data.English  \\\n",
      "0                                                    0   \n",
      "1                                                    0   \n",
      "2                                                    0   \n",
      "3                                                    0   \n",
      "4    september 19 information requested financial a...   \n",
      "..                                                 ...   \n",
      "117  please release agent wa requested directly own...   \n",
      "118  agent wa interested creating agency agent mois...   \n",
      "119  agent want continue working claro several reas...   \n",
      "120  release requested luisa alvarez agent urgently...   \n",
      "121  via email agent request release manuel contact...   \n",
      "\n",
      "                          Clasificacion  \n",
      "0               Specific request Agency  \n",
      "1               Specific request Agency  \n",
      "2               Specific request Agency  \n",
      "3               Specific request Agency  \n",
      "4               Specific request Agency  \n",
      "..                                  ...  \n",
      "117             Specific request Agency  \n",
      "118  Release Requested/ Whit out reason  \n",
      "119                      Independet FMO  \n",
      "120             Specific request Agency  \n",
      "121             Specific request Agency  \n",
      "\n",
      "[122 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "predict['Observaciones.English'] = predict['Observaciones.English'].astype(str)\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "swords = stopwords.words(\"english\")\n",
    "cleanedData=[]\n",
    "\n",
    "for text in predict['Observaciones.English']:\n",
    "    \n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(\"[^a-zA-Z0-9]\",\" \",text)\n",
    "    text = nltk.word_tokenize(text.lower())\n",
    "    text = [lemma.lemmatize(word) for word in text]\n",
    "    text = [word for word in text if word not in swords]\n",
    "    text = \" \".join(text)\n",
    "    cleanedData.append(text)\n",
    "\n",
    "predict[\"Cleaned Data.English\"] = cleanedData\n",
    "X_nuevo = vectorizer.transform(predict['Cleaned Data.English'])\n",
    "y_pred_nuevo = model.predict(X_nuevo)\n",
    "predict['Clasificacion'] = y_pred_nuevo\n",
    "\n",
    "\n",
    "predict.to_excel('resultados modelo 4.15.24.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
